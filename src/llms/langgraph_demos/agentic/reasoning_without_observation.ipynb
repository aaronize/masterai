{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fdc063-e986-48ef-babe-27baa0d93c23",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- [1] https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/\n",
    "- [2] Reasoning WithOut Observation(ReWOO): https://arxiv.org/abs/2305.18323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7809331-732b-4845-98e3-01ce3cffaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "from typing import List, TypedDict\n",
    "\n",
    "\n",
    "class ReWOO(TypedDict):\n",
    "    task: str\n",
    "    plan_string: str\n",
    "    steps: List\n",
    "    results: dict\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15474dc2-1a96-40b6-9096-bad7ed067466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70e27b4-3252-4f21-ba4b-8247eae41ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"For the following task, make plans that can solve the problem step by step. For each plan, indicate \\\n",
    "which external tool together with tool input to retrieve evidence. You can store the evidence into a \\\n",
    "variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) Google[input]: Worker that searches results from Google. Useful when you need to find short\n",
    "and succinct answers about a specific topic. The input should be a search query.\n",
    "(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general\n",
    "world knowledge and common sense. Prioritize it when you are confident in solving the problem\n",
    "yourself. Input can be any instruction.\n",
    "\n",
    "For example,\n",
    "Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\n",
    "hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\n",
    "less than Toby. How many hours did Rebecca work?\n",
    "Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\n",
    "with Wolfram Alpha. #E1 = WolframAlpha[Solve x + (2x − 10) + ((2x − 10) − 8) = 157]\n",
    "Plan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\n",
    "Plan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2 ∗ #E2 − 10) − 8]\n",
    "\n",
    "Begin! \n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ced991d-0598-45c2-a7de-74a559472224",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"what is the hometown of the 2024 australian open winner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d59d63a-2ed2-4b3c-92f2-bd30f0badd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(prompt.format(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815f16ec-6240-47f8-a709-3c7af04fc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan: Use Google to search for the hometown of the 2024 Australian Open winner. #E1 = Google[2024 Australian Open winner hometown]\n",
      "Plan: Retrieve the information about the hometown of the 2024 Australian Open winner from the search results. #E2 = LLM[What is the hometown of the 2024 Australian Open winner, given #E1]\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b734ca9f-b907-433d-864a-3bc7057c7948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Regex to match expressions of the form E#... = ...[...]\n",
    "regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*([^([^([^]+)\\]\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\n",
    "planner = prompt_template | model\n",
    "\n",
    "\n",
    "def get_plan(state: ReWOO):\n",
    "    task = state[\"task\"]\n",
    "    result = planner.invoke({\"task\": task})\n",
    "    print(\">>> result:\", result)\n",
    "    # Find all matches in the sample text\n",
    "    matches = re.findall(regex_pattern, result.content)\n",
    "    print(\">>> matchs:\", matches)\n",
    "    print(\">>> content:\", result.content)\n",
    "    print(\">>>> end\")\n",
    "    return {\"steps\": matches, \"plan_string\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9162ea68-6807-4614-a5c1-11a606ea0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executor\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a7a36e3-5554-4fda-90ed-22ad729ac3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_current_task(state: ReWOO):\n",
    "    print(\">>>\", state[\"results\"])\n",
    "    if state[\"results\"] is None:\n",
    "        return 1\n",
    "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "        return None\n",
    "    else:\n",
    "        return len(state[\"results\"]) + 1\n",
    "\n",
    "\n",
    "def tool_execution(state: ReWOO):\n",
    "    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n",
    "    _step = _get_current_task(state)\n",
    "    print(\">>>> _step:\", _step)\n",
    "    print(\">>>> steps:\", state[\"steps\"])\n",
    "    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n",
    "    _results = state[\"results\"] or {}\n",
    "    for k, v in _results.items():\n",
    "        tool_input = tool_input.replace(k, v)\n",
    "    if tool == \"Google\":\n",
    "        result = search.invoke(tool_input)\n",
    "    elif tool == \"LLM\":\n",
    "        result = model.invoke(tool_input)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    _results[step_name] = str(result)\n",
    "    return {\"results\": _results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17d48a4d-9101-4329-931e-d4619a4c6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solve_prompt = \"\"\"Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \\\n",
    "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\n",
    "contain irrelevant information.\n",
    "\n",
    "{plan}\n",
    "\n",
    "Now solve the question or task according to provided Evidence above. Respond with the answer\n",
    "directly with no extra words.\n",
    "\n",
    "Task: {task}\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "def solve(state: ReWOO):\n",
    "    plan = \"\"\n",
    "    for _plan, step_name, tool, tool_input in state[\"steps\"]:\n",
    "        _results = state[\"results\"] or {}\n",
    "        for k, v in _results.items():\n",
    "            tool_input = tool_input.replace(k, v)\n",
    "            step_name = step_name.replace(k, v)\n",
    "        plan += f\"Plan: {_plan}\\n{step_name} = {tool}[{tool_input}]\"\n",
    "    prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n",
    "    result = model.invoke(prompt)\n",
    "    return {\"result\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31f081bd-b785-4e69-a184-f24aec3aa608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define graph\n",
    "def _route(state):\n",
    "    _step = _get_current_task(state)\n",
    "    if _step is None:\n",
    "        # We have executed all tasks\n",
    "        return \"solve\"\n",
    "    else:\n",
    "        # We are still executing tasks, loop back to the \"tool\" node\n",
    "        return \"tool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a416b4d-e93c-494c-a823-116bcc71cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "graph = StateGraph(ReWOO)\n",
    "graph.add_node(\"plan\", get_plan)\n",
    "graph.add_node(\"tool\", tool_execution)\n",
    "graph.add_node(\"solve\", solve)\n",
    "graph.add_edge(\"plan\", \"tool\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "graph.add_conditional_edges(\"tool\", _route)\n",
    "graph.add_edge(START, \"plan\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd2a84f5-859f-44c4-baec-ef4bce6948a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> result: content='Plan: Use Google to search for the hometown of the 2024 Australian Open winner. #E1 = Google[2024 Australian Open winner hometown] \\nPlan: Review the search results to find the hometown of the 2024 Australian Open winner. #E2 = LLM[Review search results from #E1] \\nPlan: Confirm the hometown of the 2024 Australian Open winner. #E3 = LLM[What is the hometown of the 2024 Australian Open winner, given #E2]' response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 377, 'total_tokens': 483}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a87d26e0-a5ab-463e-9415-254930783194-0' usage_metadata={'input_tokens': 377, 'output_tokens': 106, 'total_tokens': 483}\n",
      ">>> matchs: []\n",
      ">>> content: Plan: Use Google to search for the hometown of the 2024 Australian Open winner. #E1 = Google[2024 Australian Open winner hometown] \n",
      "Plan: Review the search results to find the hometown of the 2024 Australian Open winner. #E2 = LLM[Review search results from #E1] \n",
      "Plan: Confirm the hometown of the 2024 Australian Open winner. #E3 = LLM[What is the hometown of the 2024 Australian Open winner, given #E2]\n",
      ">>>> end\n",
      "{'plan': {'plan_string': 'Plan: Use Google to search for the hometown of the 2024 Australian Open winner. #E1 = Google[2024 Australian Open winner hometown] \\nPlan: Review the search results to find the hometown of the 2024 Australian Open winner. #E2 = LLM[Review search results from #E1] \\nPlan: Confirm the hometown of the 2024 Australian Open winner. #E3 = LLM[What is the hometown of the 2024 Australian Open winner, given #E2]', 'steps': []}}\n",
      "---\n",
      ">>> None\n",
      ">>>> _step: 1\n",
      ">>>> steps: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:946\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1347\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step, timeout_exc_cls)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langgraph/pregel/executor.py:60\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:25\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     23\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2873\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2869\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2870\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2871\u001b[0m )\n\u001b[1;32m   2872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Workspace/masterai/venv/lib/python3.11/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[45], line 16\u001b[0m, in \u001b[0;36mtool_execution\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> _step:\u001b[39m\u001b[38;5;124m\"\u001b[39m, _step)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> steps:\u001b[39m\u001b[38;5;124m\"\u001b[39m, state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m _, step_name, tool, tool_input \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m _results \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _results\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"task\": task}):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af29db-a77a-4ef2-a829-266bb61b5a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
